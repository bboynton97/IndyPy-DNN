{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to build Skynet: 7 steps\n",
    "### Intro to Neural Networks\n",
    "\n",
    "\n",
    "## Pythology Session\n",
    "## September 2017\n",
    "## Brandon Boynton\n",
    "## Breast Cancer Identifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Configuration variables\n",
    "TEST_SPLIT = 0.1\n",
    "HOLE_SYMBOL = '?'\n",
    "PREDICTION_COL = 'class'\n",
    "HM_EPOCHS = 10\n",
    "LEARNING_RATE = 0.001\n",
    "HM_INPUTS = 9\n",
    "HM_OUTPUTS = 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   ~~ 1. preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clump_thickness int64\n",
      "unif_cell_size int64\n",
      "unif_cell_shape int64\n",
      "marg_adhesion int64\n",
      "single_epith_cell_size int64\n",
      "bare_nuclei object\n",
      "bland_chrom int64\n",
      "norm_nucleoli int64\n",
      "mitosis int64\n",
      "class int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('breast-cancer-wisconsin.csv') #Load CSV into pandas Dataframe\n",
    "\n",
    "#   1a. Drop any columns that are not pertinant\n",
    "df.drop(\"id\", axis=1, inplace=True) #Drop the ID column\n",
    "\n",
    "#   1b. Replace any holes in the data with an unnoticable value\n",
    "cols = list(df.columns.values) #Get all of the columns\n",
    "for col in cols:\n",
    "    print(col, df[col].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## column 'bare_nuclei' has \"?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    699.000000\n",
       "mean       3.440629\n",
       "std        3.665507\n",
       "min       -1.000000\n",
       "25%        1.000000\n",
       "50%        1.000000\n",
       "75%        5.000000\n",
       "max       10.000000\n",
       "Name: bare_nuclei, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['bare_nuclei'].replace(\"?\",-1,inplace=True)\n",
    "df['bare_nuclei']=df.bare_nuclei.apply(lambda x: pd.to_numeric(x))\n",
    "\n",
    "df.bare_nuclei.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get the mean for those that are non negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_replace_mean = df[df.bare_nuclei>-1].bare_nuclei.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    699.000000\n",
       "mean       3.544656\n",
       "std        3.601852\n",
       "min        1.000000\n",
       "25%        1.000000\n",
       "50%        1.000000\n",
       "75%        5.000000\n",
       "max       10.000000\n",
       "Name: bare_nuclei, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.bare_nuclei.replace(-1,to_replace_mean,inplace=True)\n",
    "df.bare_nuclei.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for col in cols: #for each column\\n    only_nums = [] #Initialize array for all the numbers in the array\\n    for row in df[col].tolist(): #For every row in the column\\n        if isinstance(row, (int,float,complex)): #(int, long, float, complex)):\\n            only_nums.append(row) #Add all the numbers to only_nums\\n    col_mean = np.mean(only_nums) #Get the average of all the rows\\n    new_col = df[col].tolist() #Create new column with the existing column\\n    for row in new_col: #Loop through new column\\n        if row == HOLE_SYMBOL: #Replace any holes with the average value\\n            new_col[row] = col_mean\\n    df[col] = new_col #Replace existing column with new column'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"for col in cols: #for each column\n",
    "    only_nums = [] #Initialize array for all the numbers in the array\n",
    "    for row in df[col].tolist(): #For every row in the column\n",
    "        if isinstance(row, (int,float,complex)): #(int, long, float, complex)):\n",
    "            only_nums.append(row) #Add all the numbers to only_nums\n",
    "    col_mean = np.mean(only_nums) #Get the average of all the rows\n",
    "    new_col = df[col].tolist() #Create new column with the existing column\n",
    "    for i, row in enumerate(new_col): #Loop through new column\n",
    "        if row == HOLE_SYMBOL: #Replace any holes with the average value\n",
    "            new_col[i] = col_mean\n",
    "    df[col] = new_col #Replace existing column with new column\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In other cases, you may need to drop rows, convert strings into numerical data, or clense data\n",
    "\n",
    "#    1c. Set up dataframe for the neural network\n",
    "hm_test_rows = int(len(df.index) * float(TEST_SPLIT)) #How many rows should we reserve for testing the AI\n",
    "hm_train_rows = len(df.index) - hm_test_rows #How many rows should we train on\n",
    "\n",
    "train = df.head(hm_train_rows) #Get the first # of rows for training\n",
    "test = df.tail(hm_test_rows) #Get the last # of rows for testing\n",
    "\n",
    "X = np.array(train.drop([PREDICTION_COL],1).astype(float)) #Format input data into variable X\n",
    "X = np.array(X).reshape(hm_train_rows, HM_INPUTS) #turn multidimensional array into readable shape\n",
    "y = np.array(df[PREDICTION_COL]) #get only self.prediction_col\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#   1d. Convert values into one-hot encoded tensors\n",
    "label_vals = [2,4] #Possible outputs\n",
    "\n",
    "new_y = []\n",
    "for label in y: #for each value in y\n",
    "    empty_tensor = [0,0] #create array with 0 for each unique element in y\n",
    "    modified_tensor = np.array(empty_tensor) # create new modified_tensor from empty_tensor\n",
    "    label_index = label_vals.index(label) # get the index of that element from all unique elements\n",
    "    modified_tensor[label_index] = 1 #set that index to 1\n",
    "    new_y.append(modified_tensor)\n",
    "y = new_y #replace y with the new formatted y\n",
    "\n",
    "test_X = np.array(test.drop([PREDICTION_COL],1).astype(float))\n",
    "test_X = np.array(test_X).reshape(hm_test_rows, HM_INPUTS)\n",
    "test_y = y[hm_train_rows:]\n",
    "\n",
    "y = y[:hm_train_rows]\n",
    "y = np.array(y)\n",
    "\n",
    "y_true = test_y #format test_y labels for the acuracy test\n",
    "y_true = [np.argmax(x) for x in y_true]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((69, 9), 69, 69, (630, 9))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X.shape, len(test_y), len(y_true), X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   ~~ 2. Create the neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "net = Sequential() #Create model\n",
    "\n",
    "import tensorflow as tf #Reset graph just in case\n",
    "tf.reset_default_graph()\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "net.add(Dense(HM_INPUTS,input_dim=HM_INPUTS))\n",
    "#net.add(Dense(HM_INPUTS,input_shape=(None,HM_INPUTS)))\n",
    "net.add(Dense(14))\n",
    "net.add(Dense(HM_OUTPUTS))\n",
    "#sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True) #For custom optimizer\n",
    "net.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy']) #Uses default optimizer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   ~~ 3. Train the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "630/630 [==============================] - 0s - loss: 0.6986 - acc: 0.6381     \n",
      "Epoch 2/10\n",
      "630/630 [==============================] - 0s - loss: 0.5694 - acc: 0.6492     \n",
      "Epoch 3/10\n",
      "630/630 [==============================] - 0s - loss: 0.4836 - acc: 0.7667     \n",
      "Epoch 4/10\n",
      "630/630 [==============================] - 0s - loss: 0.4099 - acc: 0.8222     \n",
      "Epoch 5/10\n",
      "630/630 [==============================] - 0s - loss: 0.3925 - acc: 0.8222     \n",
      "Epoch 6/10\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.3397 - acc: 0.812 - 0s - loss: 0.3848 - acc: 0.8349     \n",
      "Epoch 7/10\n",
      "630/630 [==============================] - 0s - loss: 0.5930 - acc: 0.8587     \n",
      "Epoch 8/10\n",
      "630/630 [==============================] - 0s - loss: 0.9323 - acc: 0.8841     \n",
      "Epoch 9/10\n",
      "630/630 [==============================] - 0s - loss: 0.9338 - acc: 0.8762     \n",
      "Epoch 10/10\n",
      "630/630 [==============================] - 0s - loss: 1.8858 - acc: 0.8730     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11f398e80>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fit(X, y, epochs=HM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Accuracy: 0.9565217391304348\n"
     ]
    }
   ],
   "source": [
    "#   3a. Get the accuracy\n",
    "\n",
    "y_scores = net.predict(test_X)\n",
    "y_scores = [np.argmax(x) for x in y_scores]\n",
    "accuracy = accuracy_score(y_true, y_scores)\n",
    "\n",
    "print(\"Network Accuracy: {}\".format(accuracy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 1,2,1,3,2,3,1,2,1\n",
      "[1 2 1 3 2 3 1 2 1]\n",
      "[[ 1.32536638  1.53314674]]\n",
      "> 9,1,2,3,4,1,1,2,7\n",
      "[9 1 2 3 4 1 1 2 7]\n",
      "[[ 4.16923618 -0.72009552]]\n"
     ]
    }
   ],
   "source": [
    "#Create infinite loop for test inferencing\n",
    "while (True):\n",
    "    inference_str = input('> ')\n",
    "    inference_tensor = inference_str.split(',')\n",
    "    inference_tensor = np.array(list(map(int, inference_tensor)))\n",
    "    p\n",
    "    inference_tensor = inference_tensor.reshape((1,HM_INPUTS))\n",
    "    results = net.predict(inference_tensor)\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
